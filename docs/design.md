# FinBot â€” Technical Design

> Natural Language Shared Finance Agent via Telegram

---

## 1. System Overview

FinBot is a Telegram-based shared finance manager for two partners. Users send free-text messages describing expenses, settlements, and queries. An LLM agent parses these into structured financial data, confirms with the user, and commits to an append-only ledger.

### 1.1 Design Goals

- **Cross-platform**: Android, iOS, Desktop via Telegram
- **Low-cost**: Runs primarily on local LLM; paid API as fallback only
- **Auditable**: Immutable raw inputs, append-only ledger, derived balances
- **Modular**: Clean separation of concerns for iterative development
- **Self-hosted**: Runs on user's Ubuntu server via Docker

---

## 2. Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Telegram Bot API      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bot Service            â”‚  Python (aiogram 3.x)
â”‚  - Message routing      â”‚  - Handles Telegram updates
â”‚  - User session mgmt    â”‚  - Inline keyboards for confirmations
â”‚  - Rate limiting        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent Orchestrator     â”‚  Multi-step state machine
â”‚  - Conversation state   â”‚  - Decides: parse / clarify / commit / query
â”‚  - Agent loop           â”‚  - Calls LLM + tools in sequence
â”‚  - Confidence gating    â”‚  - Manages clarification flow
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚         â”‚
       â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Client â”‚ â”‚  Tool Registry    â”‚
â”‚ - Ollama   â”‚ â”‚  - parse_expense  â”‚
â”‚   (primary)â”‚ â”‚  - log_expense    â”‚
â”‚ - Paid API â”‚ â”‚  - log_settlement â”‚
â”‚   (fallbk) â”‚ â”‚  - get_balance    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  - query_expenses â”‚
               â”‚  - list_categoriesâ”‚
               â”‚  - validate_settl â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  PostgreSQL 16    â”‚
               â”‚  - raw_inputs     â”‚
               â”‚  - ledger         â”‚
               â”‚  - categories     â”‚
               â”‚  - conversations  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. LLM Strategy

### 3.1 Primary: Local Model via Ollama

- **Model**: Qwen2.5-7B-Instruct (Q4_K_M quantization)
- **VRAM**: ~5.5GB on 8GB RTX 5060 Ti (leaves headroom for KV cache)
- **Performance**: Expected 30-60 tokens/sec
- **Tool calling**: Native support in Qwen2.5
- **Context management**: Keep context short â€” only current interaction + system prompt. History lives in DB, not LLM context.

### 3.2 Fallback: Paid API

- **Models**: Claude Haiku or GPT-4o-mini
- **Trigger**: When local model confidence is low or tool calling fails
- **Budget**: < $5/month target (expected < $1/month at normal usage)
- **Logging**: Every fallback call is logged with reason, input, and cost. A reporting mechanism allows tracking fallback frequency to ensure it stays within budget and to identify patterns that could be improved locally.

### 3.3 Why Not a Thinking Model

The multi-step reasoning is implemented in **application code** (the agent orchestrator), not in the LLM's chain-of-thought. Each individual LLM call is a focused task (parse this text, generate this clarification). This is more reliable and debuggable than depending on an LLM's internal reasoning, especially at 7B parameter scale.

---

## 4. Agent Orchestrator

### 4.1 Multi-Step Flow

The orchestrator is a **custom state machine** (not LangGraph â€” see [ADR-002](decisions.md#adr-002-custom-agent-loop-over-langgraph)).

States:

```
IDLE â†’ PARSING â†’ VALIDATING â†’ CLARIFYING â†’ CONFIRMING â†’ COMMITTING â†’ IDLE
                                   â†‘              â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  (user edits)
```

### 4.2 Flow Example: Expense Logging

```
User: "groceries 300 and gas 200, yesterday, split 70/30"

Step 1 â€” PARSING
  LLM extracts structured data:
    Entry 1: {amount: 300, category: "groceries", date: yesterday, split: 70/30}
    Entry 2: {amount: 200, category: "gas", date: yesterday, split: 70/30}

Step 2 â€” VALIDATING
  Code checks required fields:
    âœ“ amount, âœ“ category, âœ“ date, âœ“ split
    âœ— payer â€” MISSING

Step 3 â€” CLARIFYING
  Agent asks: "Who paid for these â€” you or partner?"
  User replies: "me"

Step 4 â€” VALIDATING (re-run)
  All fields resolved âœ“

Step 5 â€” CONFIRMING
  Bot shows structured summary with inline keyboard:
    "ğŸ“ 2 expenses:
     1. Groceries â‚ª300 â€” you paid, split 70/30 â†’ partner owes â‚ª90
     2. Gas â‚ª200 â€” you paid, split 70/30 â†’ partner owes â‚ª60
     Date: [yesterday]
     [âœ… Confirm] [âœï¸ Edit] [âŒ Cancel]"

Step 6 â€” COMMITTING
  User taps âœ… â†’ entries written to ledger
```

### 4.3 Flow Example: Query

```
User: "how much did we spend on groceries this month?"

Step 1 â€” PARSING
  LLM identifies this as a query, not an expense

Step 2 â€” TOOL CALL
  Agent calls: query_expenses(category="groceries", date_from="2025-12-01")

Step 3 â€” RESPONSE
  LLM formats: "This month you spent â‚ª2,400 on groceries across 8 transactions."
```

### 4.4 Clarification Priority

Clarification and disambiguation is **critical**, especially in early usage. The system should err on the side of asking rather than assuming. Over time, as patterns emerge (e.g., "User A always pays for groceries"), we may add smart defaults â€” but not for MVP.

---

## 5. Tool Registry

Tools are Python functions with typed schemas that the LLM can call:

| Tool | Purpose | Write? |
|------|---------|--------|
| `parse_expense` | Extract structured expense data from text | No |
| `log_expense` | Commit a validated expense to the ledger | Yes |
| `log_settlement` | Commit a validated settlement | Yes |
| `get_balance` | Derive current balance from ledger | No |
| `query_expenses` | Filter/aggregate expenses | No |
| `list_categories` | Return known categories | No |
| `create_category` | Add a new user-defined category | Yes |
| `validate_settlement` | Check settlement constraints | No |
| `get_recent_entries` | Fetch recent ledger entries (for context/edits) | No |

Each tool has:
- A JSON schema describing its parameters (used by LLM for tool calling)
- Input validation
- Logging of every invocation

---

## 6. Database Schema

### 6.1 Core Tables

```sql
-- Immutable raw inputs (never modified or deleted)
CREATE TABLE raw_inputs (
    id          UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    telegram_user_id  BIGINT NOT NULL,
    raw_text    TEXT NOT NULL,
    created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
);

-- Append-only financial ledger
CREATE TABLE ledger (
    id                  UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    raw_input_id        UUID NOT NULL REFERENCES raw_inputs(id),
    event_type          TEXT NOT NULL CHECK (event_type IN ('expense', 'settlement', 'correction')),
    amount              DECIMAL(12,2) NOT NULL,
    currency            TEXT NOT NULL DEFAULT 'ILS',
    category            TEXT,
    payer_telegram_id   BIGINT NOT NULL,
    split_payer_pct     DECIMAL(5,2) NOT NULL,
    split_other_pct     DECIMAL(5,2) NOT NULL,
    event_date          DATE NOT NULL,
    description         TEXT,
    tags                TEXT[],
    interpretation_version  INT NOT NULL DEFAULT 1,
    created_at          TIMESTAMPTZ NOT NULL DEFAULT now(),
    superseded_by       UUID REFERENCES ledger(id)
);

-- User-extensible categories
CREATE TABLE categories (
    name        TEXT PRIMARY KEY,
    created_at  TIMESTAMPTZ NOT NULL DEFAULT now()
);

-- Partner relationship mapping
CREATE TABLE partnerships (
    id          UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_a_telegram_id  BIGINT NOT NULL,
    user_b_telegram_id  BIGINT NOT NULL,
    default_currency    TEXT NOT NULL DEFAULT 'ILS',
    created_at  TIMESTAMPTZ NOT NULL DEFAULT now(),
    UNIQUE(user_a_telegram_id, user_b_telegram_id)
);
```

### 6.2 Observability Tables

```sql
-- LLM call logging (tracks local vs fallback usage)
CREATE TABLE llm_calls (
    id              UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    provider        TEXT NOT NULL,          -- 'ollama' or 'claude' or 'openai'
    model           TEXT NOT NULL,
    input_tokens    INT,
    output_tokens   INT,
    latency_ms      INT,
    is_fallback     BOOLEAN NOT NULL DEFAULT false,
    fallback_reason TEXT,                   -- why local model was bypassed
    cost_usd        DECIMAL(8,6),           -- estimated cost for paid calls
    created_at      TIMESTAMPTZ NOT NULL DEFAULT now()
);
```

### 6.3 Key Design Properties

- **`raw_inputs`**: Truly immutable. Supports reprocessing requirement.
- **`ledger`**: Append-only. Edits create new rows; old rows get `superseded_by` set.
- **Balance**: Always derived via `SELECT SUM(...)` over active (non-superseded) entries. Never stored.
- **`llm_calls`**: Every LLM interaction logged. Enables reporting on fallback frequency and cost.

---

## 7. Project Structure

```
finbot/
â”œâ”€â”€ docker-compose.yml          # Dev compose (macOS)
â”œâ”€â”€ docker-compose.prod.yml     # Prod compose (Ubuntu + GPU)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pyproject.toml              # Dependency management
â”œâ”€â”€ alembic.ini                 # DB migrations config
â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ design.md               # This file
â”‚   â””â”€â”€ decisions.md            # Architecture Decision Records
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ finbot/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # Settings via pydantic-settings
â”‚       â”‚
â”‚       â”œâ”€â”€ bot/                # Telegram layer (thin)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ handlers.py     # Message & callback handlers
â”‚       â”‚   â”œâ”€â”€ keyboards.py    # Inline keyboards (confirm/cancel/edit)
â”‚       â”‚   â”œâ”€â”€ formatters.py   # Format structured data for Telegram
â”‚       â”‚   â””â”€â”€ middleware.py   # Access control & DB session injection
â”‚       â”‚
â”‚       â”œâ”€â”€ agent/              # LLM orchestration
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ orchestrator.py # Multi-step state machine
â”‚       â”‚   â”œâ”€â”€ state.py        # Conversation state models & in-memory store
â”‚       â”‚   â”œâ”€â”€ prompts.py      # System prompts and templates
â”‚       â”‚   â””â”€â”€ llm_client.py   # Abstract LLM interface (Ollama / paid API)
â”‚       â”‚
â”‚       â”œâ”€â”€ tools/              # Tool implementations (called by agent)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ registry.py     # Tool registry + JSON schemas
â”‚       â”‚   â”œâ”€â”€ expenses.py     # parse_expense, log_expense
â”‚       â”‚   â”œâ”€â”€ settlements.py  # log_settlement, validate_settlement
â”‚       â”‚   â”œâ”€â”€ queries.py      # get_balance, query_expenses
â”‚       â”‚   â””â”€â”€ categories.py   # list/create categories
â”‚       â”‚
â”‚       â”œâ”€â”€ ledger/             # Core accounting (pure logic, no LLM)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ models.py       # SQLAlchemy ORM models
â”‚       â”‚   â”œâ”€â”€ repository.py   # DB read/write operations
â”‚       â”‚   â”œâ”€â”€ balance.py      # Balance derivation from ledger replay
â”‚       â”‚   â””â”€â”€ validation.py   # Settlement validation rules
â”‚       â”‚
â”‚       â”œâ”€â”€ reprocessing/       # Re-parse historical raw inputs (Phase 6)
â”‚       â”‚   â””â”€â”€ __init__.py
â”‚       â”‚
â”‚       â””â”€â”€ db/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ session.py      # Async DB session factory
â”‚           â””â”€â”€ migrations/     # Alembic migration versions
â”‚               â””â”€â”€ versions/
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_agent/
    â”œâ”€â”€ test_bot/
    â”œâ”€â”€ test_ledger/
    â”œâ”€â”€ test_tools/
    â””â”€â”€ fixtures/
```

### 7.1 Module Boundaries

- **`ledger/`** â€” Pure accounting. No LLM, no Telegram. Fully unit-testable.
- **`tools/`** â€” Wraps ledger operations as tool-callable functions with schemas.
- **`agent/`** â€” Owns the multi-step loop and LLM communication. `llm_client.py` is abstract â€” swap Ollama for paid API without touching anything else.
- **`bot/`** â€” Thin Telegram skin. Receives messages, passes to orchestrator, formats responses.

---

## 8. Deployment

### 8.1 Development (macOS)

- Docker Compose with PostgreSQL and Ollama (CPU mode, or no Ollama â€” use paid API for dev)
- Hot reload via volume mounts
- Local `.env` file

### 8.2 Production (Ubuntu Server)

- Docker Compose managed via Portainer
- GPU passthrough to Ollama container (NVIDIA Container Toolkit)
- PostgreSQL with persistent volume
- Ollama with model volume (persists across container restarts)

### 8.3 Hardware (Production)

| Component | Spec |
|-----------|------|
| CPU | Intel i5-13600 (20 threads) |
| RAM | 32GB DDR4 |
| GPU | NVIDIA RTX 5060 Ti 8GB |
| OS | Ubuntu (Docker host) |

---

## 9. Build Phases

| Phase | Scope | Est. Effort |
|-------|-------|-------------|
| **1. Foundation** | Project scaffold, Docker setup, DB schema + migrations, config | 1-2 days |
| **2. Telegram Bot** | aiogram bot, message reception, raw_input storage, session mgmt | 1 day |
| **3. LLM Integration** | Ollama client, abstract LLM interface, tool schemas, basic parsing | 2-3 days |
| **4. Agent Loop** | Multi-step orchestrator, confirmation flow, clarification, commit | 3-4 days |
| **5. Accounting** | Balance derivation, settlement logging + validation, basic queries | 2-3 days |
| **6. Edit & Reprocess** | Edit flow, superseding entries, reprocessing engine | 2-3 days |
| **7. Hardening** | Error handling, edge cases, prompt tuning, model benchmarking | Ongoing |

---

## 10. Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|-----------|
| 7B model misparses ambiguous input | Wrong ledger entries | Spec requires ambiguity blocking. Agent asks rather than assumes. |
| 7B tool calling unreliable | Agent loop breaks | Constrained JSON output + code-side validation. Fallback to paid API. |
| 8GB VRAM too tight for long context | Slow/OOM | Keep context minimal. History in DB, not LLM context. |
| GPU passthrough issues in Docker | Can't run local model | NVIDIA Container Toolkit is mature. Test early in Phase 1. |
| Fallback API costs exceed budget | > $5/month | Logging + alerting on `llm_calls` table. Rate-limit fallbacks. |
